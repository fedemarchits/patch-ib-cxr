experiment_name: "model_c_patchib"

data:
  json_path: "/workspace/mimic_master_official_split.jsonl"
  image_root: "/datasets/MIMIC-CXR/files"
  batch_size: 64
  num_workers: 4
  image_size: 224

model:
  vision_backbone: "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
  text_backbone: "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
  temperature: 0.1

  # Contrastive loss weights
  contrastive_mask_weight: 1.0   # Weight for L_NCE-mask (on masked embedding)
  contrastive_full_weight: 1.0   # Weight for L_NCE-full (on full embedding)

  # ============ PATCH-IB CONFIGURATION ============
  # Enable masking (Information Bottleneck)
  use_masking: true
  mask_ratio: 0.5  # Target sparsity ratio (50% of patches)

  # Sparsity loss weight (L1 penalty on mask activations)
  use_sparsity_loss: true
  sparsity_weight: 10.0
  sparsity_warmup_steps: 200

  # Consistency loss (keep masked embedding close to full embedding)
  consistency_weight: 1.0
  consistency_include_negatives: false  # Only penalize positive pairs

  # ============ LOCAL ALIGNMENT CONFIGURATION ============
  # Local alignment is essential for Patch-IB (grounding)
  use_local_alignment: true
  local_alignment_temperature: 0.7
  use_uncertainty_weighting: false
  local_alignment_weight: 100
  local_alignment_warmup_steps: 500
  # Multi-head cross-attention (thesis Section 11.1)
  local_alignment_n_heads: 4
  local_alignment_dropout: 0.1

training:
  # Early stopping on combined metric (recall + AUC)
  early_stopping_metric: "combined"

  # Combined metric weights
  combined_weights:
    recall: 0.7
    auc: 0.3

  eval_auc_every: 1

  epochs: 40
  lr: 5.0e-6
  weight_decay: 0.01
  warmup_steps: 1000
  early_stopping_patience: 7
  print_freq: 50
  device: "cuda"
  use_amp: true
  gradient_accumulation_steps: 2

  # Fine-tuning options
  freeze_backbone: false
  llrd_factor: 0.85

wandb:
  enable: true
  project: "Thesis-PatchIB"
  run_name: "model-c-patchib"
