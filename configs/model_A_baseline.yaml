experiment_name: "model_a_baseline_biomedclip"

data:
  # The path you provided
  json_path: "/workspace/mimic_moro232_labeled.jsonl"
  # ⚠️ IMPORTANT: Ask the tutor/prof where the actual IMAGE folders are.
  # I am guessing a standard path here, but you MUST verify this.
  image_root: "/datasets/MIMIC-CXR/files"
  batch_size: 48
  num_workers: 4
  image_size: 224

model:
  vision_backbone: "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
  text_backbone: "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
  mask_ratio: 0.5
  temperature: 0.1
  use_masking: false
  use_sparsity_loss: false
  # Local Alignment Configuration
  use_local_alignment: false # Enable/disable local alignment loss
  local_alignment_weight: 0.1 # Lambda weight for local loss
  local_alignment_temperature: 1.0 # Softmax temperature for attention

training:
  epochs: 40
  lr: 2.0e-5 # Lower LR for fine-tuning pretrained BiomedCLIP
  weight_decay: 0.01
  warmup_steps: 500
  early_stopping_patience: 12
  print_freq: 50
  device: "cuda"
  use_amp: true

wandb:
  enable: true
  project: "Thesis-PatchIB"
  run_name: "model-a-baseline"
