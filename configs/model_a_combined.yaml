experiment_name: "model_a_combined_metric"

data:
  json_path: "/workspace/mimic_master_official_split.jsonl"
  image_root: "/datasets/MIMIC-CXR/files"
  batch_size: 96
  num_workers: 4
  image_size: 224

model:
  vision_backbone: "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
  text_backbone: "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
  mask_ratio: 0.5
  temperature: 0.2
  contrastive_mask_weight: 1.0   # Weight for contrastive loss
  contrastive_full_weight: 1.0
  use_masking: false
  use_sparsity_loss: false

  # Contrastive loss weights (i2t + t2i)
  contrastive_weight_i2t: 0.5  # Image-to-text weight
  contrastive_weight_t2i: 0.5  # Text-to-image weight

  use_local_alignment: false
  local_alignment_weight: 0.1
  local_alignment_temperature: 0.7

training:
  # Early stopping on combined metric (recall + AUC)
  # Options: 'loss', 'recall', 'auc', 'combined'
  early_stopping_metric: "combined"

  # Combined metric weights (must sum to 1.0)
  combined_weights:
    recall: 0.7
    auc: 0.3

  # How often to compute AUC (every N epochs, since it's slower)
  eval_auc_every: 1

  epochs: 40
  lr: 5.0e-6
  weight_decay: 0.05
  warmup_steps: 1000
  early_stopping_patience: 10
  print_freq: 50
  device: "cuda"
  use_amp: true
  gradient_accumulation_steps: 2

  # Staged Training Configuration
  # Phase 1: Freeze backbone, train only heads (adapts pretrained representations to your data)
  # Phase 2: Unfreeze backbone, fine-tune everything with LLRD
  staged_training: true
  warmup_epochs: 3 # Number of epochs with frozen backbone
  warmup_lr: 1.0e-4 # Higher LR for warmup (only training heads)

  # Fine-tuning options (used in Phase 2)
  freeze_backbone: false
  llrd_factor: 0.85 # Layer-wise LR decay: early layers get 0.85x LR of next layer

wandb:
  enable: true
  project: "Thesis-PatchIB"
  run_name: "model-a-staged-training"
